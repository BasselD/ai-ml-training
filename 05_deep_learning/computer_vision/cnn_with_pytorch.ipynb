{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dbhIGhSZHPD-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbFO3iXEHQI3",
        "outputId": "3dee6f98-7779-4a83-c8cf-3cce86b4d19c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 7740550.32it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 254799.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4638570.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 10277142.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Training data: 60000 samples\n",
            "Testing data: 10000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Data preprocessing: normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Loading the dataset\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Printing the shape of the datasets\n",
        "print(f'Training data: {len(train_dataset)} samples')\n",
        "print(f'Testing data: {len(test_dataset)} samples')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -0.7412, -0.2471,  0.3725,  0.2235, -0.4980, -0.8902,\n",
            "          -0.5765,  0.0745,  0.6000,  0.5216, -0.2000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4275,\n",
            "           0.4588,  0.3882,  0.4353,  0.3725,  0.4745,  0.8196,  1.0000,\n",
            "           0.7490,  0.7176,  0.5216,  0.4039,  0.4588,  0.6706,  0.1451,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.2784,\n",
            "           0.0980,  0.1765,  0.1922,  0.1765,  0.1451,  0.3725,  0.3725,\n",
            "           0.3569,  0.3412,  0.2235,  0.1922,  0.1608,  0.0118,  0.2235,\n",
            "           0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.1765,  0.1137,\n",
            "           0.0980,  0.1922,  0.2549,  0.2235,  0.1451,  0.1137, -0.0039,\n",
            "           0.0588,  0.0431,  0.0980,  0.0980,  0.0745,  0.0431, -0.0196,\n",
            "           0.3255, -0.4118, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5765,  0.3098,\n",
            "           0.1451,  0.0118,  0.1137,  0.0745,  0.0745,  0.0275,  0.1608,\n",
            "           0.1608,  0.0431,  0.0275,  0.0275,  0.0275, -0.0196,  0.0980,\n",
            "           0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.1373,\n",
            "           0.4745,  0.0431,  0.1451,  0.1922,  0.0431, -0.0196, -0.0039,\n",
            "          -0.0667,  0.0118,  0.0431, -0.0667,  0.0980,  0.0275,  0.1765,\n",
            "          -0.8902, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "           0.7333,  0.2392,  0.0745,  0.0588, -0.0353, -0.1373, -0.1373,\n",
            "          -0.1059, -0.1529, -0.1216, -0.0824, -0.0039,  0.1137, -0.3961,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9686, -1.0000,\n",
            "          -0.8039,  0.2392,  0.0745, -0.0196, -0.0667, -0.0667, -0.1373,\n",
            "          -0.0824, -0.0824, -0.1373, -0.0667, -0.0039,  0.1294, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -0.0353,  0.2235,  0.0118, -0.1216, -0.1373, -0.2000,\n",
            "          -0.1216, -0.2157, -0.0510, -0.0824,  0.0118, -0.1059, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -0.0196,  0.3255, -0.0039, -0.0667, -0.1686, -0.1529,\n",
            "          -0.1843, -0.2627, -0.0510, -0.1059,  0.0118, -0.2863, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843,\n",
            "          -1.0000, -0.2314,  0.3412,  0.0118, -0.1216, -0.1843, -0.1059,\n",
            "          -0.1686, -0.2000, -0.1216, -0.1843,  0.0431, -0.4980, -1.0000,\n",
            "          -0.9686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843,\n",
            "          -1.0000, -0.4824,  0.3569,  0.0588,  0.0118, -0.2314, -0.2157,\n",
            "          -0.0667, -0.2000, -0.1529, -0.2314,  0.0588, -0.5294, -1.0000,\n",
            "          -0.9686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843,\n",
            "          -1.0000, -0.5608,  0.3412,  0.0588, -0.0039, -0.2157, -0.1529,\n",
            "          -0.0824, -0.3333, -0.1686, -0.1373,  0.0588, -0.4824, -1.0000,\n",
            "          -0.9686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -0.5922,  0.1765,  0.0118, -0.1373, -0.2157, -0.2863,\n",
            "          -0.2000, -0.2627, -0.3490, -0.1843, -0.0353, -0.4824, -1.0000,\n",
            "          -0.9686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843,\n",
            "          -1.0000, -0.4824,  0.3098,  0.0980,  0.1608,  0.1608, -0.0039,\n",
            "           0.0745,  0.1922,  0.1451,  0.1451,  0.1608, -0.2471, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -0.6471, -0.0353, -0.2627, -0.1843, -0.2471, -0.0667,\n",
            "          -0.0510, -0.1686, -0.2314, -0.1216, -0.3176, -0.1059, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -0.1686, -0.3020, -0.5451, -0.6078, -0.7098, -0.6078,\n",
            "          -0.4824, -0.5608, -0.6078, -0.4118, -0.4118,  0.0745, -0.8275,\n",
            "          -1.0000, -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -1.0000,\n",
            "          -0.7725,  0.1608, -0.1059, -0.1686, -0.0196, -0.3020, -0.2157,\n",
            "           0.0431, -0.0824,  0.0275,  0.0275,  0.0275, -0.0196, -0.1216,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -0.2157, -0.1686, -0.1059, -0.2863,  0.0745, -0.5137, -0.2000,\n",
            "           0.0275, -0.3020,  0.0588, -0.1216,  0.0275, -0.1529,  0.0588,\n",
            "          -0.7098, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "           0.1451, -0.2157, -0.1529, -0.2314,  0.1294, -0.5137, -0.1686,\n",
            "           0.0275, -0.3176,  0.0431, -0.1843,  0.2549, -0.0824, -0.0510,\n",
            "          -0.4667, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7412,\n",
            "          -0.0510, -0.1529, -0.2471, -0.2157,  0.0980, -0.4431, -0.1686,\n",
            "          -0.0039, -0.3333,  0.0980, -0.1843,  0.1765,  0.0980, -0.1059,\n",
            "          -0.3020, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5137,\n",
            "          -0.0667, -0.1216, -0.2000, -0.1373,  0.0745, -0.4118, -0.1686,\n",
            "           0.1294, -0.3647,  0.1294, -0.1529, -0.0824,  0.2078, -0.0824,\n",
            "          -0.1843, -0.8588, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4824,\n",
            "          -0.0510, -0.2000, -0.1216, -0.0824,  0.0275, -0.4275, -0.1843,\n",
            "           0.2235, -0.3961,  0.0745,  0.0588, -0.3490,  0.4039,  0.0118,\n",
            "          -0.0510, -0.7255, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
            "          -0.0039, -0.3647, -0.0196,  0.0431, -0.0667, -0.3804, -0.2157,\n",
            "           0.3255, -0.3490,  0.0118,  0.3725, -0.5294,  0.2784,  0.0588,\n",
            "           0.1451, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.1686,\n",
            "           0.0118, -0.5137,  0.0980,  0.1294, -0.1529, -0.3333, -0.3490,\n",
            "           0.2392, -0.3333,  0.0118,  0.3725, -0.6235,  0.1451,  0.0431,\n",
            "           0.0588, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.0824,\n",
            "          -0.0667, -0.3804,  0.0980,  0.1922, -0.2000, -0.3020, -0.1373,\n",
            "           0.0745, -0.2471,  0.1765,  0.5373, -0.3490,  0.1294,  0.0588,\n",
            "           0.0431, -0.3961, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2078,\n",
            "          -0.0510, -0.3176,  0.0980,  0.2078, -0.1216, -0.2627, -0.5922,\n",
            "           0.1137, -0.2157, -0.3490,  0.1922, -0.3333,  0.2549,  0.0431,\n",
            "          -0.2157, -0.9059, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9686,\n",
            "          -1.0000, -0.9843, -1.0000, -0.7255, -0.9686, -0.7412, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]) 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "image, label = train_dataset[3]  # Replace 'random_index' with an actual integer index\n",
        "print(image, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcY0lEQVR4nO3deXCV5f3+8Sv7IXsgkd0EEykossgUi4hxo4hFRRG3VoJttY4bLmhl6nzdihaVVmulDtqqKMUOilXAilVRqyDQqdIiVdZghRgiEJKQnIQk9+8Phs/PGCi570Ag+H7N5I/z5LnOsySTK885Tz6Jcc45AQAgKfZQ7wAA4PBBKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQyl8i+Tl5WnChAkH9DlPO+009evXb7/rFRcXKyYmRs8888wB3T6AA4tSOAKsW7dOP/vZz3TMMccoEokoPT1dw4YN06OPPqqamppWP//mzZt199136+OPP279zraxvLw8xcTE7PejPZTV1/c3Pj5eHTt21ODBgzVx4kStWrXqUO8ejhDxh3oH0DoLFizQuHHjlJSUpPHjx6tfv36qq6vT+++/r9tuu02ffPKJZsyY0aptbN68Wffcc4/y8vI0cODAoOfIzc1VTU2NEhISWrUvvh555BFVVVXZ49dee02zZ8/Wb37zG2VnZ9vyk08+uU33K9SIESM0fvx4Oee0Y8cOrVixQs8++6ymT5+uqVOn6pZbbjnUu4h2jlJoxzZs2KBLL71Uubm5evvtt9W1a1f73HXXXae1a9dqwYIFh3AP/7+YmBhFIpE23+6YMWOaPP7yyy81e/ZsjRkzRnl5eW2+P63Vu3dv/ehHP2qy7Fe/+pXOPfdc3XrrrerTp4/OOeecfeaj0agSExMVG8uLBNg7vjPasQcffFBVVVX6wx/+0KQQ9igoKNDEiRP/53OsX79e48aNU8eOHZWcnKzvfe97TYrknXfe0Xe/+11J0pVXXrnPl1tWrVql008/XcnJyerevbsefPDBJp/f23sKEyZMUGpqqjZt2qQxY8YoNTVVOTk5mjRpkhoaGprkt27dqiuuuELp6enKzMxUUVGRVqxY0eqXfu666y4lJCSorKys2eeuvvpqZWZmKhqNStr9UtTo0aP1xhtvaODAgYpEIjruuOM0d+7cZtny8nLddNNN6tmzp5KSklRQUKCpU6eqsbGxyXolJSX69NNPtWvXruBj6NSpk1544QXFx8drypQptvydd95RTEyMXnjhBd15553q3r27kpOTVVFRIUlaunSpzj77bGVkZCg5OVmFhYX64IMPmjx3ZWWlbrrpJuXl5SkpKUlHHXWURowYoX/+85+2zpo1azR27Fh16dJFkUhEPXr00KWXXqodO3YEHxMOHUqhHZs3b56OOeaY4Jc+SktLdfLJJ2vhwoW69tprNWXKFEWjUZ133nl6+eWXJUl9+/bVvffeK2n3D8nnnntOzz33nE499VR7nu3bt+vss8/WgAEDNG3aNPXp00c///nP9de//nW/+9DQ0KCRI0eqU6dOevjhh1VYWKhp06Y1ecmrsbFR5557rmbPnq2ioiJNmTJFJSUlKioqCjrur7viiitUX1+vP//5z02W19XV6cUXX9TYsWObXOGsWbNGl1xyiUaNGqUHHnhA8fHxGjdunP72t7/ZOtXV1SosLNTzzz+v8ePH67e//a2GDRumyZMnN3t5Z/Lkyerbt682bdrUquM4+uijVVhYqA8//NB+6O9x3333acGCBZo0aZLuv/9+JSYm6u2339app56qiooK3XXXXbr//vtVXl6uM844Q8uWLbPsNddco9///vcaO3aspk+frkmTJqlDhw76z3/+Y+dp5MiR+vDDD3XDDTfo8ccf19VXX63169ervLy8VceEQ8ShXdqxY4eT5M4///wWZ3Jzc11RUZE9vummm5wk9/e//92WVVZWul69erm8vDzX0NDgnHNu+fLlTpJ7+umnmz1nYWGhk+Rmzpxpy2pra12XLl3c2LFjbdmGDRuaPUdRUZGT5O69994mzzlo0CA3ePBge/zSSy85Se6RRx6xZQ0NDe6MM87Y537ty0MPPeQkuQ0bNtiyoUOHupNOOqnJenPnznWS3KJFi2xZbm6uk+ReeuklW7Zjxw7XtWtXN2jQIFt23333uZSUFLd69eomz3nHHXe4uLg49/nnnzc7B1/fn32R5K677rp9fn7ixIlOkluxYoVzzrlFixY5Se6YY45x1dXVtl5jY6M79thj3ciRI11jY6Mtr66udr169XIjRoywZRkZGf9zmx999JGT5ObMmbPf/Uf7wJVCO7Xnt8G0tLTg53jttdc0ZMgQnXLKKbYsNTVVV199tYqLi1t8R0tqamqT17kTExM1ZMgQrV+/vkX5a665psnj4cOHN8m+/vrrSkhI0FVXXWXLYmNjdd1117Xo+fdn/PjxWrp0qdatW2fLZs2apZ49e6qwsLDJut26ddMFF1xgj9PT0zV+/Hh99NFH+vLLLyVJc+bM0fDhw5WVlaWvvvrKPs466yw1NDTovffes/wzzzwj59wBeX8jNTVV0u6XfL6uqKhIHTp0sMcff/yx1qxZo8svv1xbt261/du5c6fOPPNMvffee/YyV2ZmppYuXarNmzfvdZsZGRmSpIULF6q6urrVx4BDj1Jop9LT0yU1/wHgY+PGjfrOd77TbHnfvn3t8y3Ro0cPxcTENFmWlZWl7du37zcbiUSUk5PzP7MbN25U165dlZyc3GS9goKCFu3f/lxyySVKSkrSrFmzJEk7duzQ/Pnz9cMf/rDZcRUUFDRb1rt3b0m73zeRdr/E9PrrrysnJ6fJx1lnnSVJ2rJlywHZ72/ac5fVN39R6NWrV5PHa9askbS7LL65j0899ZRqa2vt/YAHH3xQK1euVM+ePTVkyBDdfffdTQq7V69euuWWW/TUU08pOztbI0eO1OOPP877Ce0Ydx+1U+np6erWrZtWrlx5qHdFcXFxe13uWvCfXveVbUtZWVkaPXq0Zs2apf/7v//Tiy++qNra2mZ3+bRUY2OjRowYodtvv32vn99TIgfaypUrFRcX16wEvn6VsGf/JOmhhx7a5y3Ge646Lr74Yg0fPlwvv/yy3njjDT300EOaOnWq5s6dq1GjRkmSpk2bpgkTJuiVV17RG2+8oRtvvFEPPPCAPvzwQ/Xo0eMAHyUONkqhHRs9erRmzJihJUuWaOjQod753NxcffbZZ82Wf/rpp/Z5Sc1+M25rubm5WrRokaqrq5tcLaxdu/aAbWP8+PE6//zztXz5cs2aNUuDBg3S8ccf32y9tWvXyjnX5JysXr1akuwloPz8fFVVVdmVQVv4/PPP9e6772ro0KH7fUkxPz9f0u5fLFqyj127dtW1116ra6+9Vlu2bNGJJ56oKVOmWClI0gknnKATTjhBd955pxYvXqxhw4bpiSee0C9/+cvWHRjaHC8ftWO33367UlJS9NOf/lSlpaXNPr9u3To9+uij+8yfc845WrZsmZYsWWLLdu7cqRkzZigvL0/HHXecJCklJUWSDtndJCNHjtSuXbv05JNP2rLGxkY9/vjjB2wbo0aNUnZ2tqZOnap33313n1cJmzdvtjuzpN3v7cycOVMDBw5Uly5dJO3+7XrJkiVauHBhs3x5ebnq6+vt8YG4JXXbtm267LLL1NDQoF/84hf7XX/w4MHKz8/Xww8/3OQP+/bYc3tuQ0NDs5eBjjrqKHXr1k21tbWSdh//149H2l0QsbGxtg7aF64U2rH8/Hz96U9/0iWXXKK+ffs2+YvmxYsXa86cOf9z1tEdd9yh2bNna9SoUbrxxhvVsWNHPfvss9qwYYNeeukl+wOn/Px8ZWZm6oknnlBaWppSUlJ00kknNXuZ4mAZM2aMhgwZoltvvVVr165Vnz599Oqrr2rbtm2SDsyVTEJCgi699FL97ne/U1xcnC677LK9rte7d2/95Cc/0fLly9W5c2f98Y9/VGlpqZ5++mlb57bbbtOrr76q0aNHa8KECRo8eLB27typf//733rxxRdVXFxsf009efJkO+ctebN59erVev755+WcU0VFhVasWKE5c+aoqqpKv/71r3X22Wfv9zliY2P11FNPadSoUTr++ON15ZVXqnv37tq0aZMWLVqk9PR0zZs3T5WVlerRo4cuuugiDRgwQKmpqXrzzTe1fPlyTZs2TZL09ttv6/rrr9e4cePUu3dv1dfX67nnnlNcXJzGjh3bgjOPw86hvfkJB8Lq1avdVVdd5fLy8lxiYqJLS0tzw4YNc4899piLRqO23jdvSXXOuXXr1rmLLrrIZWZmukgk4oYMGeLmz5/fbBuvvPKKO+6441x8fHyT20ALCwvd8ccf32z9oqIil5uba4/3dUtqSkpKs+xdd93lvvmtWVZW5i6//HKXlpbmMjIy3IQJE9wHH3zgJLkXXnihBWdpt73dkrrHsmXLnCT3/e9/f6/Z3Nxc94Mf/MAtXLjQ9e/f3yUlJbk+ffrs9XbMyspKN3nyZFdQUOASExNddna2O/nkk93DDz/s6urqmpyDfe3PN0myj9jYWJeZmekGDRrkJk6c6D755JNm6++5JXVft4t+9NFH7sILL3SdOnVySUlJLjc311188cXurbfecs7tvrX4tttucwMGDHBpaWkuJSXFDRgwwE2fPt2eY/369e7HP/6xy8/Pd5FIxHXs2NGdfvrp7s0339zv8eDwFONcC94NBA5Df/nLX3TBBRfo/fff17Bhw1r9fCtWrNDAgQM1c+ZMXXHFFc0+n5eXp379+mn+/Pmt3hZwuOI9BbQL35z22tDQoMcee0zp6ek68cQTD8g2nnzySaWmpurCCy88IM8HtEe8p4B24YYbblBNTY2GDh2q2tpazZ07V4sXL9b999/f7JZLX/PmzdOqVas0Y8YMXX/99fbGOvBtRCmgXTjjjDM0bdo0zZ8/X9FoVAUFBXrsscd0/fXXt/q5b7jhBpWWluqcc87RPffccwD2Fmi/eE8BAGB4TwEAYCgFAIBp8XsKh3rUAVomZNrmaaed5p05//zzvTNbt271zkjS888/7535+j+Baak+ffp4Z0L+QOvMM8/0zkgKmkIacu5a++9bcfhqybsFXCkAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAA0+L/p8BAvHCjRo3yztx8881B2/rmv61sicTERO9MNBr1zqSlpXlnJKlfv37emc6dO3tniouLvTP19fXemZKSEu+MJO3YscM7k5SU5J3p3r27d+att97yztx4443eGbQOA/EAAF4oBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGUgAAGAbiecrPz/fO3H333d6Z0tJS74wkJScne2diY/1/N2hsbPTOhAyPk6SePXsG5XyFHFNIJmSwnRR2/nbt2uWd2bZtm3cmZIheeXm5d0aSJk2aFJQDA/EAAJ4oBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGUgAAGEoBAGCYkupp+vTp3ploNOqdCZm+KUmpqanemUgk4p0JmdhZXV3tnQndVsgk0pDzEPJ1SkpK8s6Eamho8M6EnO+Q7/F+/fp5ZyRp5syZ3pkFCxYEbetIw5RUAIAXSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGUgAAGEoBAGAoBQCAoRQAAIaBeJ6GDBninbn55pu9M2VlZd4ZSdq+fbt3Ji0tzTuza9cu70youro670xmZuaB35G9qKio8M6EDjtsKyHnOyMj4yDsyd5NmjSpzbZ1pGEgHgDAC6UAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAAATf6h3oL1ZtmyZd2bJkiXemfPOO887I0lLly71zsTH+38bJCcne2e2bt3qnZHCBrR99dVX3ploNOqdCTkPIedbChu+l5OTE7QtXyHn4Y477jgIe4LW4koBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGUgAAmBjnnGvRijExB3tf8DXr1q0Lyr377rvembKyMu9MY2Ojd6aqqso7I0mVlZVBOV9xcXHemV27dnlnQgfiJSQkeGdCBtVlZGR4ZxYtWuSdmTdvnncGrdOSH/dcKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAAATNpnrWyxkmFl9fb135pRTTvHOSNKUKVOCcr6qq6u9MyHnQZI6dOjgnampqfHOhHxtQzK1tbXeGUmKjW2b3+FCtsNwuyMHVwoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAMOUVE+hkz59lZSUBOXWrVvnnenVq5d3JhqNemcqKyu9M5LU2NjonQnZv5DpoFVVVd6ZnJwc74wU9r0XckwbN270zuDIwZUCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMAzEO8KEDEBLS0vzzoQMqUtKSvLOSFJFRYV3JjEx0TsTMkSvrq7OOxOqrYYxbtmypU22g8MTVwoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAMBCvDYQMqQsZOCdJX3zxhXemf//+3pmQY6qtrfXOSJJzzjuTkJDgnWloaPDORCIR70xNTY13Rgob2Jedne2d2bRpk3cmRHx82I+fthoM+G3FlQIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwDMQ7whQXF3tnQobbJSYmemeysrK8M1LYMYUMTevUqZN3Zvv27d6Z0IFuIQMFQ762DJz7duNKAQBgKAUAgKEUAACGUgAAGEoBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgmJJ6hKmpqfHONDY2HoQ9OXDbiYuL885EIhHvTMj+hUxJzc7O9s5IUlpaWlDOV0JCQptsB4cnrhQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGUgAAGEoBAGAoBQCAYSBeG2irgXOSVF9f750pKyvzztTV1XlnQobHhQrZVsgxdejQwTuzZcsW74wk5eTkeGeqqqqCtoVvL64UAACGUgAAGEoBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgGEgXhuIjfXv3tAhemlpad6ZrKws70x1dbV3pmPHjt6ZUF999ZV3Jjk52TuTkZHhnQkZvBcqJibGO5Obm3sQ9qS5kOGNOPi4UgAAGEoBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGgXhtIHS4XYiysjLvzMqVK70z//3vf70zIQPnJCkajXpnOnfu7J0JGVRXXFzsnQk5Hils+F5JSYl3plu3bt4ZHDm4UgAAGEoBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGgXhHmOHDh3tn1q9f753ZuHGjdyZ0EFxFRYV3Jj093TsTMnCupqbGOxMyeE+SunbtGpTz1aVLF+/MUUcd5Z3ZsmWLd0aSYmP9f5dty6GU7R1XCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAE+Occy1aMSbmYO9Lu9BWExp79uzpnZGk22+/3TsTMiU1ZOJpdna2d0aS1q5d651JSUnxzvTq1cs7U15e7p0JmeDalkKmuFZWVnpnHnnkEe8MWqclP+65UgAAGEoBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAAAm/lDvQHsTMtwuxMiRI4Nyq1at8s5EIhHvTEVFhXcmLy/POyNJmzZt8s706dPHOxPytf3iiy+8M/379/fOSFJpaal3plOnTt6Z7du3e2e6d+/unSkoKPDOSGEDEtFyXCkAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAw0C8w1To0LR//etf3pm4uDjvTGJioncmKSnJOxMq5JhChAzRCx2qGI1GvTM9e/b0zoQMO2zLAYkMxDu4uFIAABhKAQBgKAUAgKEUAACGUgAAGEoBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhoF4bSBk8FdJSUnQtiKRiHemqqrKOxMf7/+tU19f752RpA4dOgTlfIXsX8hwu7YcDFhdXe2d6dy5s3dm06ZN3pmcnBzvDA4+rhQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBgKAUAgKEUAACGUgAAGEoBAGAoBQCAYSBeGzj66KO9MyGD1qSwQXWJiYnemZDBew0NDd4ZKeyYQmRlZXlnQobohR5PSG7Dhg3emWOPPdY7U1pa6p3JyMjwzkhSx44dvTPbtm0L2ta3EVcKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAADDlNQ2EBcX552JjQ3r6+rqau9McnKydyYhIcE7U1dX552RwibGOue8M6mpqd6ZkCmptbW13hlJ6t69u3fmH//4h3fm1FNP9c6UlJR4Z0KnxYZMs2VKastxpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMA/HaQHZ2tncmMTExaFtlZWXemX79+nlnIpGId6aiosI7I4Wdi5BBdWlpad6ZkH2LRqPeGUnq37+/d2bBggXemfLycu9MyHkIGWwnhQ/SQ8twpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMk6XaQMhAvNjYsL7eunWrdyYjI8M7EzKUrKSkxDsjhQ1b2759u3dm586d3pnQr1Nbqaqq8s6EnLvGxkbvTMj5lqSuXbt6Zz777LOgbX0bHd7f0QCANkUpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAMBCvDaSmpnpnqqurg7aVlZUVlPMViUS8M3V1dUHbChm+l5OT450pKyvzzqSkpHhnQvZNChusmJ+f750JGW4XMhgwZDuSlJaWFpRDy3ClAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwTEltA8cee6x3ZsOGDUHbCpleGiJkKmZycnLQtqLRqHdm8eLF3pnLL7/cOxMywfWtt97yzkhh5zwkk5mZ6Z3ZuXOndyb0e3zRokVBObQMVwoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAAylAAAwlAIAwFAKAABDKQAADKUAADCUAgDAxDjnXItWjIk52PtyxAoZmlZfXx+0rZABaI2Njd6Z/Px878zGjRu9M5LUo0cP70xxcXHQtoAjWUt+3HOlAAAwlAIAwFAKAABDKQAADKUAADCUAgDAUAoAAEMpAAAMpQAAMJQCAMBQCgAAQykAAEyLJ7W1cG4eAKAd40oBAGAoBQCAoRQAAIZSAAAYSgEAYCgFAIChFAAAhlIAABhKAQBg/h9KPmzEf6c6JQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Transform image back to a format suitable for display\n",
        "image = image.squeeze(0)  \n",
        "\n",
        "# Get clothing type based on label\n",
        "clothing_types = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "clothing_type = clothing_types[label]\n",
        "\n",
        "# Plot the image with label\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Clothing Type: {clothing_type}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M7B9NI0GHW6N"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module): #The CNN class inherits from nn.Module and defines the architecture of the neural network.\n",
        "    def __init__(self):\n",
        "        # we'll build 1 conv layer with max pooling\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)  # 1 input channel, 32 output channels, 3x3 kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 pooling\n",
        "        self.fc1 = nn.Linear(13*13*32, 100)  # Flattened dimensions after pooling\n",
        "        self.fc2 = nn.Linear(100, 10)  # 10 classes for FashionMNIST\n",
        "#The forward method defines the forward pass of the network, specifying how input data flows through the layers\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 13*13*32)  # Flatten\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.fc2(x)\n",
        "        return nn.Softmax(dim=1)(x)\n",
        "\n",
        "model = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYQXFP23HcoL",
        "outputId": "37e1b1d4-db21-43ad-d51b-53d6912b4033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 1.7287398681640624\n",
            "Epoch 2/10, Loss: 1.6681228606541951\n",
            "Epoch 3/10, Loss: 1.6129674882888794\n",
            "Epoch 4/10, Loss: 1.5715553172429402\n",
            "Epoch 5/10, Loss: 1.559471510887146\n",
            "Epoch 6/10, Loss: 1.553053243192037\n",
            "Epoch 7/10, Loss: 1.5483681617736818\n",
            "Epoch 8/10, Loss: 1.5442821836471559\n",
            "Epoch 9/10, Loss: 1.540566241900126\n",
            "Epoch 10/10, Loss: 1.5361587794621785\n"
          ]
        }
      ],
      "source": [
        "# Setting up the loss and optimizer\n",
        "#The loss function is defined using nn.CrossEntropyLoss(), which is suitable for multi-class classification tasks.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model for 10 epochs\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader: #The training data is iterated over in batches using a data loader (train_loader).\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFubvmv-Hfmx",
        "outputId": "17fbbc41-c4ee-4f3c-d57e-55638e4b6384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy on test set: 90.08%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Model accuracy on test set: {accuracy}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8yRZqjlJ5HY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the model (optional)\n",
        "torch.save(model.state_dict(), 'fashion_mnist_cnn.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "model = FashionCNN()  # Create a new model instance\n",
        "model.load_state_dict(torch.load('fashion_mnist_cnn.pt'))\n",
        "model.eval()  # Set the model to evaluation mode (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flowers Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the data transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the Flowers dataset\n",
        "train_dataset = datasets.ImageFolder('flowers/train', data_transforms['train'])\n",
        "val_dataset = datasets.ImageFolder('flowers/val', data_transforms['val'])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the CNN model\n",
        "class FlowerCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlowerCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.max_pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(256*56*56, 128)\n",
        "        self.fc2 = nn.Linear(128, 5)  # 5 classes: daisy, dandelion, roses, sunflowers, tulips\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = x.view(-1, 256*56*56)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = FlowerCNN()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item()}')\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / len(val_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}, Val Loss: {val_loss / len(val_loader)}, Val Acc: {accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
