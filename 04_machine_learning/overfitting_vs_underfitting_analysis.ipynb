{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FREqD9kaarzX"
   },
   "source": [
    "# Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias vs Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Here's a breakdown of bias and variance in machine learning, illustrated with examples:**\n",
    "\n",
    "**Bias:**\n",
    "\n",
    "- **Meaning:** It's the model's tendency to make consistent errors due to underlying simplifying assumptions or limitations. It's like a stubborn friend who always underestimates distances, even with a map.\n",
    "- **High Bias:** The model is too simplistic and can't capture the true patterns in the data. It's like trying to fit a straight line to a curved relationship.\n",
    "- **Example:** A linear regression model used for a non-linear relationship will have high bias.\n",
    "\n",
    "**Variance:**\n",
    "\n",
    "- **Meaning:** It's the model's sensitivity to small fluctuations in the training data. Like a weathervane spinning wildly in a light breeze, it overreacts to minor changes.\n",
    "- **High Variance:** The model is overly complex and fits the training data too closely, including noise and irrelevant patterns. It's like memorizing every detail of a map without understanding the general layout.\n",
    "- **Example:** A decision tree with too many branches, fitting every quirk of the training data, will have high variance and struggle to generalize to new examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vb](https://miro.medium.com/v2/resize:fit:1400/1*9hPX9pAO3jqLrzt0IE3JzA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "\n",
    "- **Trade-off:** There's often a trade-off between bias and variance. Reducing one often increases the other. It's like balancing a seesaw—finding the sweet spot is crucial.\n",
    "- **Goal:** Aim for a model that has low bias and low variance, striking a balance between capturing the true patterns and generalizing well to new data.\n",
    "- **Regularization:** Techniques like L1/L2 regularization and cross-validation can help control bias and variance, guiding your model to the optimal balance.\n",
    "\n",
    "**Visualizing Bias and Variance:**\n",
    "\n",
    "Imagine a dartboard:\n",
    "\n",
    "- **High Bias:** Darts consistently miss the target in a similar direction (underfitting).\n",
    "- **High Variance:** Darts are scattered all over the board, hitting both the target and outer rings (overfitting).\n",
    "- **Low Bias and Low Variance:** Darts are clustered tightly around the bullseye (ideal model).\n",
    "\n",
    "**Understanding bias and variance is essential for building accurate and generalizable machine learning models. By recognizing their effects and using techniques to control them, you can create models that make reliable predictions in the real world.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fitting.png](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Overfitting:** _High Variance and Low Bias_ </br>\n",
    "Overfitting occurs when a model learns the training data too well, to the extent that it captures noise or random fluctuations in the data as well as the underlying patterns. In other words, the model becomes too complex or too flexible, memorizing the training examples instead of generalizing from them. As a result, an overfitted model performs exceptionally well on the training data but performs poorly on new, unseen data.\n",
    "\n",
    "Signs of overfitting include:\n",
    "\n",
    "- High accuracy or performance on the training data.\n",
    "- Low accuracy or poor performance on the validation or test data.\n",
    "- Large differences between training and validation/test performance.\n",
    "\n",
    "2. **Underfitting:** _Low Variance and High Bias_</br>\n",
    "Underfitting occurs when a model is not able to capture the underlying patterns or relationships in the training data, leading to poor performance both on the training data and new data. An underfitted model is often too simple or inflexible to adequately represent the complexity of the data.\n",
    "\n",
    "Signs of underfitting include:\n",
    "\n",
    "- Low accuracy or poor performance on both training and validation/test data.\n",
    "- The model is unable to capture important patterns or trends in the data.\n",
    "- High bias and low variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address overfitting, several strategies can be employed:\n",
    "\n",
    "- Simplify the model by reducing its complexity, such as by using fewer features, reducing the number of model parameters, or applying regularization techniques.\n",
    "- Increase the amount of training data to provide more diverse examples for the model to learn from.\n",
    "- Employ techniques like cross-validation to evaluate the model's performance on multiple subsets of the data.\n",
    "- Use ensemble methods that combine multiple models to mitigate the impact of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address underfitting, several strategies can be employed:\n",
    "\n",
    "- Increase the model's complexity, such as by adding more features, using a more sophisticated model architecture, or increasing the number of model parameters.\n",
    "- Collect more relevant data if possible.\n",
    "- Improve the quality of the input features by adding more informative or derived features.\n",
    "- Reduce regularization or constraints that might be excessively limiting the model's flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Detecting and Preventing: Overfitting and Underfitting__\n",
    "\n",
    "## Step 1: Import Required Libraries\n",
    "\n",
    "- Import the required libraries and functions\n",
    "- Use an inbuilt data set from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "q4iMA-0PaJNV"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGMZuMLBa8BR"
   },
   "source": [
    "- Let's create the X and y variables using `make_classification`\n",
    "\n",
    "- Create a sample size of 9000 and a feature of 18 with n-information as 4, n-redundant as 12, and  random_state as 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "notL_o6BaJNW"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification( n_samples =9000, n_features=18, n_informative=4, n_redundant= 12, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "0Q1h5jAzPs-M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.15631115 -1.69009525  0.85714501 ...  0.24655728 -2.68791625\n",
      "   0.21728147]\n",
      " [ 1.12057112 -0.06407922  1.04214442 ...  0.46288361 -0.97242942\n",
      "   1.05363474]\n",
      " [ 0.74357671 -0.82491074 -1.79508674 ... -1.54410869 -0.52434322\n",
      "  -1.72745768]\n",
      " ...\n",
      " [ 1.80220878  0.18937296 -1.07116603 ... -1.48428913 -0.58342376\n",
      "  -0.32505131]\n",
      " [ 0.80949164 -0.18957207  0.12596869 ... -0.35277068 -0.74154152\n",
      "   0.1857882 ]\n",
      " [ 2.0372558   0.27704441  1.74492448 ...  2.13645951 -0.67826815\n",
      "   1.9827086 ]]\n",
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.156311</td>\n",
       "      <td>-1.690095</td>\n",
       "      <td>0.857145</td>\n",
       "      <td>-0.552380</td>\n",
       "      <td>-1.297134</td>\n",
       "      <td>2.410491</td>\n",
       "      <td>1.213942</td>\n",
       "      <td>1.095740</td>\n",
       "      <td>-0.271120</td>\n",
       "      <td>-0.208286</td>\n",
       "      <td>-0.745402</td>\n",
       "      <td>0.158750</td>\n",
       "      <td>-0.121244</td>\n",
       "      <td>0.415272</td>\n",
       "      <td>-1.466593</td>\n",
       "      <td>0.246557</td>\n",
       "      <td>-2.687916</td>\n",
       "      <td>0.217281</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.120571</td>\n",
       "      <td>-0.064079</td>\n",
       "      <td>1.042144</td>\n",
       "      <td>-0.083166</td>\n",
       "      <td>-1.097919</td>\n",
       "      <td>0.907019</td>\n",
       "      <td>-1.221173</td>\n",
       "      <td>1.151107</td>\n",
       "      <td>0.454202</td>\n",
       "      <td>-0.555523</td>\n",
       "      <td>-0.423824</td>\n",
       "      <td>-0.342339</td>\n",
       "      <td>-0.552415</td>\n",
       "      <td>0.543628</td>\n",
       "      <td>-1.125092</td>\n",
       "      <td>0.462884</td>\n",
       "      <td>-0.972429</td>\n",
       "      <td>1.053635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.743577</td>\n",
       "      <td>-0.824911</td>\n",
       "      <td>-1.795087</td>\n",
       "      <td>-1.140818</td>\n",
       "      <td>0.828695</td>\n",
       "      <td>0.884580</td>\n",
       "      <td>-0.414306</td>\n",
       "      <td>-1.261001</td>\n",
       "      <td>-0.478853</td>\n",
       "      <td>1.277968</td>\n",
       "      <td>-1.249176</td>\n",
       "      <td>-0.534983</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>0.668052</td>\n",
       "      <td>-0.346653</td>\n",
       "      <td>-1.544109</td>\n",
       "      <td>-0.524343</td>\n",
       "      <td>-1.727458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.435744</td>\n",
       "      <td>1.577253</td>\n",
       "      <td>0.288327</td>\n",
       "      <td>0.915041</td>\n",
       "      <td>0.309522</td>\n",
       "      <td>-1.914877</td>\n",
       "      <td>-1.998745</td>\n",
       "      <td>0.029314</td>\n",
       "      <td>0.456918</td>\n",
       "      <td>-0.461416</td>\n",
       "      <td>0.723707</td>\n",
       "      <td>-0.199109</td>\n",
       "      <td>-0.067241</td>\n",
       "      <td>0.421007</td>\n",
       "      <td>0.749434</td>\n",
       "      <td>0.289394</td>\n",
       "      <td>1.800016</td>\n",
       "      <td>0.801596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.726817</td>\n",
       "      <td>0.238554</td>\n",
       "      <td>-0.486792</td>\n",
       "      <td>0.397939</td>\n",
       "      <td>0.580280</td>\n",
       "      <td>-0.861943</td>\n",
       "      <td>0.621715</td>\n",
       "      <td>-0.525683</td>\n",
       "      <td>-0.307491</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.247341</td>\n",
       "      <td>0.055955</td>\n",
       "      <td>0.409927</td>\n",
       "      <td>-0.822130</td>\n",
       "      <td>0.624040</td>\n",
       "      <td>-0.407364</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>-0.414297</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>0.830859</td>\n",
       "      <td>1.965363</td>\n",
       "      <td>-0.665370</td>\n",
       "      <td>-0.923464</td>\n",
       "      <td>-0.110722</td>\n",
       "      <td>-0.249474</td>\n",
       "      <td>1.244931</td>\n",
       "      <td>0.057567</td>\n",
       "      <td>1.497159</td>\n",
       "      <td>0.336089</td>\n",
       "      <td>-1.929889</td>\n",
       "      <td>-2.391172</td>\n",
       "      <td>-1.664827</td>\n",
       "      <td>0.535802</td>\n",
       "      <td>-1.652897</td>\n",
       "      <td>-1.149231</td>\n",
       "      <td>1.137957</td>\n",
       "      <td>0.788071</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>0.480028</td>\n",
       "      <td>0.653986</td>\n",
       "      <td>0.835577</td>\n",
       "      <td>-0.966696</td>\n",
       "      <td>-0.749638</td>\n",
       "      <td>0.829746</td>\n",
       "      <td>0.204524</td>\n",
       "      <td>0.719419</td>\n",
       "      <td>1.301058</td>\n",
       "      <td>-0.452328</td>\n",
       "      <td>-0.107936</td>\n",
       "      <td>-0.236334</td>\n",
       "      <td>-1.297658</td>\n",
       "      <td>0.563042</td>\n",
       "      <td>-0.718714</td>\n",
       "      <td>1.249289</td>\n",
       "      <td>0.411169</td>\n",
       "      <td>1.128434</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>1.802209</td>\n",
       "      <td>0.189373</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>-1.460649</td>\n",
       "      <td>-0.137728</td>\n",
       "      <td>1.274105</td>\n",
       "      <td>0.092904</td>\n",
       "      <td>-0.212706</td>\n",
       "      <td>0.635148</td>\n",
       "      <td>0.831388</td>\n",
       "      <td>-2.243735</td>\n",
       "      <td>-1.804862</td>\n",
       "      <td>-1.117498</td>\n",
       "      <td>1.931215</td>\n",
       "      <td>-1.859241</td>\n",
       "      <td>-1.484289</td>\n",
       "      <td>-0.583424</td>\n",
       "      <td>-0.325051</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>0.809492</td>\n",
       "      <td>-0.189572</td>\n",
       "      <td>0.125969</td>\n",
       "      <td>-0.080578</td>\n",
       "      <td>-0.407116</td>\n",
       "      <td>0.522411</td>\n",
       "      <td>-1.027597</td>\n",
       "      <td>0.372593</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>-0.012773</td>\n",
       "      <td>-0.613109</td>\n",
       "      <td>-0.443309</td>\n",
       "      <td>-0.160150</td>\n",
       "      <td>0.739815</td>\n",
       "      <td>-0.750670</td>\n",
       "      <td>-0.352771</td>\n",
       "      <td>-0.741542</td>\n",
       "      <td>0.185788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>2.037256</td>\n",
       "      <td>0.277044</td>\n",
       "      <td>1.744924</td>\n",
       "      <td>-2.070455</td>\n",
       "      <td>-1.921794</td>\n",
       "      <td>2.737032</td>\n",
       "      <td>0.094480</td>\n",
       "      <td>1.734202</td>\n",
       "      <td>2.137146</td>\n",
       "      <td>-0.792301</td>\n",
       "      <td>-0.738201</td>\n",
       "      <td>-0.461309</td>\n",
       "      <td>-2.369102</td>\n",
       "      <td>1.669865</td>\n",
       "      <td>-2.098555</td>\n",
       "      <td>2.136460</td>\n",
       "      <td>-0.678268</td>\n",
       "      <td>1.982709</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     2.156311 -1.690095  0.857145 -0.552380 -1.297134  2.410491  1.213942   \n",
       "1     1.120571 -0.064079  1.042144 -0.083166 -1.097919  0.907019 -1.221173   \n",
       "2     0.743577 -0.824911 -1.795087 -1.140818  0.828695  0.884580 -0.414306   \n",
       "3    -1.435744  1.577253  0.288327  0.915041  0.309522 -1.914877 -1.998745   \n",
       "4    -0.726817  0.238554 -0.486792  0.397939  0.580280 -0.861943  0.621715   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8995  0.830859  1.965363 -0.665370 -0.923464 -0.110722 -0.249474  1.244931   \n",
       "8996  0.480028  0.653986  0.835577 -0.966696 -0.749638  0.829746  0.204524   \n",
       "8997  1.802209  0.189373 -1.071166 -1.460649 -0.137728  1.274105  0.092904   \n",
       "8998  0.809492 -0.189572  0.125969 -0.080578 -0.407116  0.522411 -1.027597   \n",
       "8999  2.037256  0.277044  1.744924 -2.070455 -1.921794  2.737032  0.094480   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0     1.095740 -0.271120 -0.208286 -0.745402  0.158750 -0.121244  0.415272   \n",
       "1     1.151107  0.454202 -0.555523 -0.423824 -0.342339 -0.552415  0.543628   \n",
       "2    -1.261001 -0.478853  1.277968 -1.249176 -0.534983  0.078454  0.668052   \n",
       "3     0.029314  0.456918 -0.461416  0.723707 -0.199109 -0.067241  0.421007   \n",
       "4    -0.525683 -0.307491  0.200192  0.247341  0.055955  0.409927 -0.822130   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8995  0.057567  1.497159  0.336089 -1.929889 -2.391172 -1.664827  0.535802   \n",
       "8996  0.719419  1.301058 -0.452328 -0.107936 -0.236334 -1.297658  0.563042   \n",
       "8997 -0.212706  0.635148  0.831388 -2.243735 -1.804862 -1.117498  1.931215   \n",
       "8998  0.372593  0.014116 -0.012773 -0.613109 -0.443309 -0.160150  0.739815   \n",
       "8999  1.734202  2.137146 -0.792301 -0.738201 -0.461309 -2.369102  1.669865   \n",
       "\n",
       "            14        15        16        17   18  \n",
       "0    -1.466593  0.246557 -2.687916  0.217281  1.0  \n",
       "1    -1.125092  0.462884 -0.972429  1.053635  0.0  \n",
       "2    -0.346653 -1.544109 -0.524343 -1.727458  1.0  \n",
       "3     0.749434  0.289394  1.800016  0.801596  0.0  \n",
       "4     0.624040 -0.407364  0.605788 -0.414297  0.0  \n",
       "...        ...       ...       ...       ...  ...  \n",
       "8995 -1.652897 -1.149231  1.137957  0.788071  0.0  \n",
       "8996 -0.718714  1.249289  0.411169  1.128434  1.0  \n",
       "8997 -1.859241 -1.484289 -0.583424 -0.325051  1.0  \n",
       "8998 -0.750670 -0.352771 -0.741542  0.185788  0.0  \n",
       "8999 -2.098555  2.136460 -0.678268  1.982709  0.0  \n",
       "\n",
       "[9000 rows x 19 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.hstack((X,y.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few reasons why sklearn's make_classification function generates continuous target values between 0 and 1 rather than discrete 0/1 labels:\n",
    "\n",
    "- It allows generating soft binary classification datasets, where the targets indicate probability or degree of belonging to a class rather than absolute 0/1 labels.\n",
    "\n",
    "- Continuous values allow measuring model output as probabilities rather than strict classes during evaluation. This enables using metrics like log-loss that require probability estimates.\n",
    "\n",
    "- It provides more information to the learning algorithm about the data structure, as opposed to bare 0/1 labels.\n",
    "\n",
    "- Continuous labels can be easily converted to discrete 0/1 by thresholding, for example **setting >= 0.5 as 1 and < 0.5 as 0**. The opposite is harder.\n",
    "\n",
    "- Having continuous labels directly enables using make_classification with regression models, not just classifiers.\n",
    "\n",
    "- Discrete 0/1 labels could lead to perfect predictions on training data, making it hard to evaluate overfitting. Soft targets avoid this issue.\n",
    "\n",
    "- Most real-world classification datasets have some ambiguity, uncertanity or human judgement involved in labeling. Continuous values simulate that better.\n",
    "\n",
    "So in summary, continuous soft targets add more nuance, flexibility and realism compared to strict 0/1 labels for the synthetic datasets generated using make_classification. The targets can be discretized later if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeJhPRBnbK1m"
   },
   "source": [
    "## Step 2: Split the Dataset into Train and Test Datasets\n",
    "\n",
    "- Let's split the data into 70 for training and 30 for testing.\n",
    "\n",
    " - Create an empty list for **train_scores** and **test_scores**.\n",
    " - Create the values. (Here, we are checking for 21 values.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "ZKbNPYpyaJNX"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll be using an ML Algo called Decision Tree Classifier\n",
    "- Definintion: </br>\n",
    "A Decision Tree Classifier is a popular [[Supervised Learning]] algorithm used for both [[Classification]] and [[Regression]] tasks. It creates a tree-like model where each internal node represents a feature or attribute, each branch represents a decision rule, and each leaf node represents a class label (in the case of classification) or a numeric value (in the case of regression).\n",
    "- We'll be controlling a hyperparameter value called max depth, which controls the number of splits or layer (complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree algorithm evaluates each feature and threshold combination to find the one that best separates the data into distinct classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dt2](https://eloquentarduino.github.io/wp-content/uploads/2020/08/DecisionTree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dt](https://miro.medium.com/v2/resize:fit:1358/0*LE5dtoUiXduhrad1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective** \n",
    "- We'll be increasing the complexity of the tree branches gradually and observe the accuracy.\n",
    "- increasing complexity -> moving closer to overfitting or capture the nuances and noise in the data\n",
    "- increasing complexity for decision trees can be done in multiple ways, we'll be using `max_depth` which adjusts the number of layers in the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBowhDWSRAQh"
   },
   "source": [
    "- Now, let’s create a for loop for the model and decision.\n",
    "\n",
    "  - Pass the “i” values\n",
    "  - Check how the model will perform at different depths\n",
    "  - Fit the model and create a **train_yhat**\n",
    "  - Predict the model for **X_train**\n",
    "  - Set the accuracy score for the train\n",
    "  - Do the same for the test data set\n",
    "  - Append the values to the empty list\n",
    "  - Print the output (keep it up to 3 decimal places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "toqeImLuaJNX"
   },
   "outputs": [],
   "source": [
    "# create empty lists\n",
    "train_scores, test_scores = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "3g9o0oBnaJNX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define max depth values\n",
    "values = list(range(1,21))\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3614,
     "status": "ok",
     "timestamp": 1682511593601,
     "user": {
      "displayName": "Prerna Karn",
      "userId": "16431587453626938972"
     },
     "user_tz": -330
    },
    "id": "d5iLb-XWaJNY",
    "outputId": "b178a629-eadf-425d-9673-de077c43496b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1 \t| train score:0.662 \t| test score:0.666\n",
      "max_depth=2 \t| train score:0.704 \t| test score:0.707\n",
      "max_depth=3 \t| train score:0.792 \t| test score:0.792\n",
      "max_depth=4 \t| train score:0.838 \t| test score:0.837\n",
      "max_depth=5 \t| train score:0.871 \t| test score:0.852\n",
      "max_depth=6 \t| train score:0.895 \t| test score:0.876\n",
      "max_depth=7 \t| train score:0.913 \t| test score:0.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=8 \t| train score:0.932 \t| test score:0.881\n",
      "max_depth=9 \t| train score:0.947 \t| test score:0.883\n",
      "max_depth=10 \t| train score:0.958 \t| test score:0.881\n",
      "max_depth=11 \t| train score:0.971 \t| test score:0.873\n",
      "max_depth=12 \t| train score:0.978 \t| test score:0.870\n",
      "max_depth=13 \t| train score:0.985 \t| test score:0.870\n",
      "max_depth=14 \t| train score:0.989 \t| test score:0.865\n",
      "max_depth=15 \t| train score:0.993 \t| test score:0.869\n",
      "max_depth=16 \t| train score:0.996 \t| test score:0.869\n",
      "max_depth=17 \t| train score:0.997 \t| test score:0.867\n",
      "max_depth=18 \t| train score:0.999 \t| test score:0.863\n",
      "max_depth=19 \t| train score:1.000 \t| test score:0.866\n",
      "max_depth=20 \t| train score:1.000 \t| test score:0.859\n"
     ]
    }
   ],
   "source": [
    "for i in values:\n",
    "    #define my model\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    #train or fit the model on the training dataset\n",
    "    model.fit(X_train, y_train)\n",
    "    #run prediction for training\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    train_accu = accuracy_score(y_train, y_hat_train) #actual vs predicted y values\n",
    "    #run prediction for testing\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    test_accu = accuracy_score(y_test, y_hat_test) #actual vs predicted y values\n",
    "\n",
    "    #append the calculated values to our lists\n",
    "    train_scores.append(train_accu)\n",
    "    test_scores.append(test_accu)\n",
    "\n",
    "    #print results for each i (max_depth)\n",
    "    print(f'max_depth={i} \\t| train score:{train_accu:.3f} \\t| test score:{test_accu:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v31zSP6BUcWQ"
   },
   "source": [
    "__Observation:__\n",
    "\n",
    "- We got the accuracy for multiple parameter values for each train and test data sets.\n",
    "\n",
    "- Now, let's plot this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1682511598378,
     "user": {
      "displayName": "Prerna Karn",
      "userId": "16431587453626938972"
     },
     "user_tz": -330
    },
    "id": "rdlMqhBYaJNZ",
    "outputId": "0ae487d4-f258-42b9-95c2-c9605e6faa75"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(par_values, train_scores, '-o', label='Train Data', color='slateblue')\n",
    "plt.plot(par_values, test_scores, '-o', label='Test Data', color='orange')\n",
    "plt.xticks(par_values)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('max_depth (model complexity)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzJnh6_PVFlT"
   },
   "source": [
    "__Observations:__\n",
    "\n",
    "- Here, you can see that for one depth train, the low accuracy is around 84%\n",
    "and the test is 82%.\n",
    "\n",
    "\n",
    "- So, there is scope for improvement with low accuracy.\n",
    "\n",
    "\n",
    "- Hence, this is referred to as underfitting.\n",
    "\n",
    "\n",
    "- Whereas in the overfitting problem, you see the depth is 20.\n",
    "\n",
    "\n",
    "- It is able to predict 100% on the training set, whereas in the test it is performing poorly, at 93."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like `max_depth` between 5 and 6 is the sweet spot for an appropriate fitting (good balance)\n",
    "- We are sacrificing very high accuracy in the training dataset to increase the chances of getting a consistent high score for the testing and new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we fix this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Regularization - the idea here is to reduce the complexity of your algorithm and shrink your parameters\n",
    "- Using less depth or complex hyperparamters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **While DecisionTreeClassifier in scikit-learn doesn't have explicit L1/L2 regularization hyperparameters like some other models, you can effectively control its complexity and prevent overfitting using these techniques:**\n",
    "\n",
    "**1. Pre-pruning:**\n",
    "\n",
    "- **`max_depth`:** Limits the maximum depth of the tree, preventing it from becoming overly complex. Start with a reasonable value (e.g., 5 or 10) and adjust based on validation performance.\n",
    "- **`min_samples_split`:** Specifies the minimum number of samples required to split an internal node. Higher values create simpler trees. Try values like 2, 5, or 10.\n",
    "- **`min_samples_leaf`:** Sets the minimum number of samples required to be at a leaf node. Helps avoid overfitting to noisy data points. Experiment with values like 1, 2, or 5.\n",
    "\n",
    "**2. Post-pruning:**\n",
    "\n",
    "- **`ccp_alpha`:** Activates Cost Complexity Pruning, which prunes branches that don't provide sufficient information gain to justify their complexity. Start with a small value (e.g., 0.01) and increase as needed.\n",
    "\n",
    "**3. Hyperparameter Tuning:**\n",
    "\n",
    "- Employ techniques like GridSearchCV or RandomizedSearchCV to systematically explore different hyperparameter combinations and find the optimal settings for your dataset.\n",
    "\n",
    "**4. Ensemble Methods:**\n",
    "\n",
    "- Combine multiple decision trees using methods like Random Forests or Gradient Boosting, which inherently reduce overfitting due to averaging or boosting effects.\n",
    "\n",
    "\n",
    "\n",
    "Remember, the optimal hyperparameter values depend on your specific dataset and problem. Experimentation and careful evaluation are key to finding the best settings for your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can automate as above or use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load sample dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25)\n",
    "\n",
    "# Create a decision tree with pre-pruning and post-pruning\n",
    "clf = DecisionTreeClassifier(max_depth=5, min_samples_split=2, min_samples_leaf=1, ccp_alpha=0.01)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Perform Hyperparameter Tuning with GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters** are the parameters of a machine learning model that are not learned during training. They are typically set by the user before training begins. For example, the number of layers in a neural network is a hyperparameter.\n",
    "\n",
    "**Hyperparameter tuning** is the process of finding the best hyperparameter settings for a machine learning model. This is done by trying different values for the hyperparameters and evaluating the model's performance on a hold-out dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the parameter grid for GridSearchCV\n",
    "- Perform hyperparameter tuning using GridSearchCV\n",
    "- Fit the model with the best parameters\n",
    "- Evaluate the model on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "VfxAlNiIaJNZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing A GridSearch for Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 11362,
     "status": "ok",
     "timestamp": 1682511616888,
     "user": {
      "displayName": "Prerna Karn",
      "userId": "16431587453626938972"
     },
     "user_tz": -330
    },
    "id": "zQX1gu3NaJNZ",
    "outputId": "9f53451a-1049-4e03-da3e-f376b6e0e47b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [2, 4, 6, 10, 20],\n",
       "                         &#x27;min_samples_split&#x27;: [5, 10, 20, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [2, 4, 6, 10, 20],\n",
       "                         &#x27;min_samples_split&#x27;: [5, 10, 20, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 10, 20],\n",
       "                         'min_samples_split': [5, 10, 20, 50, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_grid = {'criterion' :['gini', 'entropy'], 'max_depth':[2,4,6,10,20], 'min_samples_split':[5,10,20, 50, 100]}\n",
    "clf= GridSearchCV(DecisionTreeClassifier(), para_grid, cv=3, n_jobs=-1, scoring=\"accuracy\")\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1682511624930,
     "user": {
      "displayName": "Prerna Karn",
      "userId": "16431587453626938972"
     },
     "user_tz": -330
    },
    "id": "nACAiniDaJNZ",
    "outputId": "803969be-43b1-4488-fe79-b4d023a0d1a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, min_samples_split=5)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZS-JUmdVWxSU"
   },
   "source": [
    "__Observation:__\n",
    "\n",
    "- The best estimators/hyperparameters are `criterion='entropy', max_depth=10, min_samples_split=50`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uuBogzU9AzQ"
   },
   "source": [
    "- Let's print the accuracy\n",
    "for both test and train to work on the overfitting problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "ORDAOZrxaJNa",
    "outputId": "40c2a490-4525-44b6-faf7-88bdd03f801a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821428571428571\n",
      "0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, clf.best_estimator_.predict(X_train)))\n",
    "print(accuracy_score(y_test, clf.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**:\n",
    "> The GridSearchCV performed 150 trials and evaluations: _2 x 5 x 5 x 3_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYsIaf1WhvsK"
   },
   "source": [
    "__Observations:__\n",
    "\n",
    "- Previously, for sample set 10, it was 98%, and the difference was around 4%.\n",
    "- However, the difference has now been reduced.\n",
    "- We have to further fine-tune it to make the difference as close as possible.\n",
    "- That is when we can claim that the overfitting problem has been resolved.\n",
    "- For underfitting problems, we usually try out different models to increase the accuracy.\n",
    "\n",
    "That's how we prevent underfitting and overfitting problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.973210</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.973210</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.973210</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.973210</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.348269</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001189      0.000559         0.000592        0.000224   \n",
       "1       0.000905      0.000217         0.000725        0.000137   \n",
       "2       0.001287      0.000663         0.000939        0.000041   \n",
       "3       0.001525      0.000297         0.000517        0.000114   \n",
       "4       0.000309      0.000082         0.000192        0.000029   \n",
       "\n",
       "  param_criterion param_max_depth param_min_samples_split  \\\n",
       "0            gini               2                       5   \n",
       "1            gini               2                      10   \n",
       "2            gini               2                      20   \n",
       "3            gini               2                      50   \n",
       "4            gini               2                     100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.973684   \n",
       "1  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.973684   \n",
       "2  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.973684   \n",
       "3  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.973684   \n",
       "4  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.342105   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           1.000000           0.945946         0.973210        0.022070   \n",
       "1           1.000000           0.945946         0.973210        0.022070   \n",
       "2           1.000000           0.945946         0.973210        0.022070   \n",
       "3           1.000000           0.945946         0.973210        0.022070   \n",
       "4           0.351351           0.351351         0.348269        0.004359   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4               41  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GS = pd.DataFrame(clf.cv_results_)\n",
    "df_GS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_9 <= 0.72\n",
      "|   |--- feature_16 <= -0.69\n",
      "|   |   |--- feature_15 <= 0.75\n",
      "|   |   |   |--- feature_9 <= -0.58\n",
      "|   |   |   |   |--- feature_16 <= -1.72\n",
      "|   |   |   |   |   |--- feature_2 <= 1.99\n",
      "|   |   |   |   |   |   |--- feature_15 <= 0.39\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= -1.04\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  -1.04\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_15 >  0.39\n",
      "|   |   |   |   |   |   |   |--- feature_13 <= -1.13\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_13 >  -1.13\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 <= 1.63\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 1.46\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_2 >  1.46\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= 1.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  1.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 >  1.63\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_2 >  1.99\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_16 >  -1.72\n",
      "|   |   |   |   |   |--- feature_9 <= -1.00\n",
      "|   |   |   |   |   |   |--- feature_15 <= 0.72\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= 0.94\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  0.94\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 <= 1.02\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 >  1.02\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_15 >  0.72\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_9 >  -1.00\n",
      "|   |   |   |   |   |   |--- feature_11 <= -1.85\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 1.27\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  1.27\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_11 >  -1.85\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= -1.92\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  -1.92\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 <= 0.93\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 <= -1.60\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 >  -1.60\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_5 >  0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 >  0.93\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= 0.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  0.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.59\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.59\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |--- feature_9 >  -0.58\n",
      "|   |   |   |   |--- feature_16 <= -1.15\n",
      "|   |   |   |   |   |--- feature_15 <= 0.41\n",
      "|   |   |   |   |   |   |--- feature_7 <= 1.98\n",
      "|   |   |   |   |   |   |   |--- feature_3 <= 1.53\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 1.81\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_4 <= -1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 1.95\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  1.95\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_4 >  -1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= -1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  -1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  1.81\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 <= -1.26\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 <= -2.54\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 >  -2.54\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 >  -1.26\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_3 >  1.53\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_7 >  1.98\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_15 >  0.41\n",
      "|   |   |   |   |   |   |--- feature_16 <= -2.00\n",
      "|   |   |   |   |   |   |   |--- feature_13 <= -1.63\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= -1.75\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  -1.75\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_13 >  -1.63\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_16 >  -2.00\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= 0.67\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= 0.92\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 <= -1.22\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_17 <= 0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_17 >  0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 >  -1.22\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  0.92\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.44\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.44\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  0.67\n",
      "|   |   |   |   |   |   |   |   |--- feature_16 <= -1.45\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_16 >  -1.45\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_16 >  -1.15\n",
      "|   |   |   |   |   |--- feature_15 <= -0.36\n",
      "|   |   |   |   |   |   |--- feature_5 <= 1.34\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= -0.65\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 <= 1.05\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 >  1.05\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 <= -0.77\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 1.07\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  1.07\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 >  -0.77\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 <= -1.12\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 >  -1.12\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  -0.65\n",
      "|   |   |   |   |   |   |   |   |--- feature_14 <= -1.94\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_14 >  -1.94\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 <= 0.01\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 <= -1.56\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 >  -1.56\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 >  0.01\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_5 >  1.34\n",
      "|   |   |   |   |   |   |   |--- feature_13 <= -0.63\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= -1.43\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 <= 0.47\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 >  0.47\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= -0.04\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  -0.04\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  -1.43\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 2.36\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.23\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  0.23\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 >  2.36\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_13 >  -0.63\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 1.91\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_17 <= -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= -1.93\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  -1.93\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_17 >  -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  1.91\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 0.28\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= 0.95\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  0.95\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  0.28\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= -1.43\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  -1.43\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |--- feature_15 >  -0.36\n",
      "|   |   |   |   |   |   |--- feature_0 <= 1.15\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 0.95\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= -0.10\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  -0.10\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_14 <= -1.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_14 >  -1.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  0.95\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 <= 0.92\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 >  0.92\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  1.15\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= 0.30\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 <= -0.88\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 <= 1.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 <= 1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 >  1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 >  1.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -1.34\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -1.34\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 >  -0.88\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -0.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -0.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  0.30\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 0.87\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -0.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 <= 0.65\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 >  0.65\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -0.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  0.87\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 <= -1.31\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 >  -1.31\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_15 >  0.75\n",
      "|   |   |   |--- feature_8 <= 0.22\n",
      "|   |   |   |   |--- feature_16 <= -2.02\n",
      "|   |   |   |   |   |--- feature_16 <= -2.46\n",
      "|   |   |   |   |   |   |--- feature_8 <= 0.03\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= -1.98\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  -1.98\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 <= -0.07\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 >  -0.07\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_12 <= 0.13\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_12 >  0.13\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  0.03\n",
      "|   |   |   |   |   |   |   |--- feature_7 <= 1.79\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 <= -1.37\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 >  -1.37\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_7 >  1.79\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_16 >  -2.46\n",
      "|   |   |   |   |   |   |--- feature_9 <= -0.76\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_9 >  -0.76\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= 1.06\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 0.43\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  0.43\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  1.06\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 <= -0.33\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 1.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 >  1.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 >  -0.33\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_16 >  -2.02\n",
      "|   |   |   |   |   |--- feature_2 <= 1.71\n",
      "|   |   |   |   |   |   |--- feature_2 <= 1.21\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_2 >  1.21\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= 1.05\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  1.05\n",
      "|   |   |   |   |   |   |   |   |--- feature_16 <= -1.26\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -0.64\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -0.64\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= -0.41\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  -0.41\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_16 >  -1.26\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_2 >  1.71\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_8 >  0.22\n",
      "|   |   |   |   |--- feature_12 <= -0.97\n",
      "|   |   |   |   |   |--- feature_0 <= 1.21\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  1.21\n",
      "|   |   |   |   |   |   |--- feature_15 <= 0.85\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= -0.22\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= -0.35\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= 0.77\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  0.77\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  -0.35\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  -0.22\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_15 >  0.85\n",
      "|   |   |   |   |   |   |   |--- feature_12 <= -1.18\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_12 >  -1.18\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 <= -1.17\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 >  -1.17\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= 0.92\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 1.13\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  1.13\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  0.92\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_12 >  -0.97\n",
      "|   |   |   |   |   |--- feature_4 <= -1.21\n",
      "|   |   |   |   |   |   |--- feature_0 <= 1.15\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= -1.54\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  -1.54\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  1.15\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.45\n",
      "|   |   |   |   |   |   |   |   |--- feature_14 <= -0.85\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 <= -1.09\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_14 <= -1.25\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_14 >  -1.25\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 >  -1.09\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 <= -0.92\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 >  -0.92\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_14 >  -0.85\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.45\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= -0.78\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  -0.78\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.42\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.42\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_4 >  -1.21\n",
      "|   |   |   |   |   |   |--- feature_1 <= -0.94\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_1 >  -0.94\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= -0.88\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  -0.88\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 <= -0.92\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_12 <= -0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_12 >  -0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 <= 0.85\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 >  0.85\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 >  -0.92\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.69\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  0.69\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |--- feature_16 >  -0.69\n",
      "|   |   |--- feature_7 <= 0.60\n",
      "|   |   |   |--- feature_15 <= -1.37\n",
      "|   |   |   |   |--- feature_8 <= 1.62\n",
      "|   |   |   |   |   |--- feature_3 <= -1.68\n",
      "|   |   |   |   |   |   |--- feature_10 <= -2.90\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_10 >  -2.90\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_3 >  -1.68\n",
      "|   |   |   |   |   |   |--- feature_16 <= 0.83\n",
      "|   |   |   |   |   |   |   |--- feature_3 <= -1.52\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 0.57\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 1.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  1.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  0.57\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_3 >  -1.52\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_16 >  0.83\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 2.38\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  2.38\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_8 >  1.62\n",
      "|   |   |   |   |   |--- feature_15 <= -2.18\n",
      "|   |   |   |   |   |   |--- feature_12 <= -3.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_12 >  -3.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_15 >  -2.18\n",
      "|   |   |   |   |   |   |--- feature_3 <= -0.88\n",
      "|   |   |   |   |   |   |   |--- feature_13 <= -2.52\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_13 >  -2.52\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 <= -2.15\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 <= 0.55\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 >  0.55\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_17 <= 2.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_17 >  2.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 >  -2.15\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= -1.63\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  -1.63\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_3 >  -0.88\n",
      "|   |   |   |   |   |   |   |--- feature_4 <= 0.08\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_4 >  0.08\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_15 >  -1.37\n",
      "|   |   |   |   |--- feature_15 <= -1.15\n",
      "|   |   |   |   |   |--- feature_12 <= -1.29\n",
      "|   |   |   |   |   |   |--- feature_16 <= -0.46\n",
      "|   |   |   |   |   |   |   |--- feature_16 <= -0.62\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 1.26\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 2.25\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 >  2.25\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  1.26\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_16 >  -0.62\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_16 >  -0.46\n",
      "|   |   |   |   |   |   |   |--- feature_3 <= -0.61\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 1.47\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  1.47\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -0.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 1.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  1.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -0.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_3 >  -0.61\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= 0.24\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  0.24\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_12 >  -1.29\n",
      "|   |   |   |   |   |   |--- feature_10 <= 0.22\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 1.11\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  1.11\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_10 >  0.22\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_15 >  -1.15\n",
      "|   |   |   |   |   |--- feature_7 <= 0.48\n",
      "|   |   |   |   |   |   |--- feature_0 <= 1.79\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 1.06\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= -1.44\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 <= -0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 >  -0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 <= -1.45\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 >  -1.45\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  -1.44\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_4 <= -0.06\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= -0.06\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  -0.06\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_4 >  -0.06\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  1.06\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 1.07\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  0.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  1.07\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_2 <= -0.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_12 <= -1.09\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_12 >  -1.09\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_2 >  -0.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= -1.62\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  -1.62\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_0 >  1.79\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= 0.96\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 <= -0.66\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 >  -0.66\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  0.96\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  0.48\n",
      "|   |   |   |   |   |   |--- feature_13 <= 1.22\n",
      "|   |   |   |   |   |   |   |--- feature_7 <= 0.48\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_7 >  0.48\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 <= -1.62\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 0.62\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 >  0.62\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 >  -1.62\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -0.89\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= -1.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  -1.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -0.89\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_13 >  1.22\n",
      "|   |   |   |   |   |   |   |--- feature_17 <= 1.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_17 >  1.19\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 <= -1.39\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_12 >  -1.39\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_7 >  0.60\n",
      "|   |   |   |--- feature_3 <= -0.72\n",
      "|   |   |   |   |--- feature_15 <= -2.83\n",
      "|   |   |   |   |   |--- feature_16 <= 3.20\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_16 >  3.20\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_15 >  -2.83\n",
      "|   |   |   |   |   |--- feature_8 <= 2.29\n",
      "|   |   |   |   |   |   |--- feature_15 <= -1.57\n",
      "|   |   |   |   |   |   |   |--- feature_3 <= -1.60\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 0.49\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  0.49\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= -1.78\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_14 <= -3.90\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_14 >  -3.90\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  -1.78\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_3 >  -1.60\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 <= -1.61\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 >  -1.61\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= -1.59\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  -1.59\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_15 >  -1.57\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= 0.30\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 1.42\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.69\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 <= -0.15\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_15 >  -0.15\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  1.69\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  1.42\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.46\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  1.46\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= 0.12\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  0.12\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  0.30\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 0.60\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  0.60\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 <= -2.25\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.79\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  0.79\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 >  -2.25\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= 1.11\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  1.11\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |--- feature_8 >  2.29\n",
      "|   |   |   |   |   |   |--- feature_8 <= 2.90\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= -2.13\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  -2.13\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= 1.51\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 <= -0.67\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_16 >  -0.67\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.61\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  0.61\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  1.51\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -1.48\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -1.48\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 <= 1.33\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 >  1.33\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_8 >  2.90\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 0.37\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  0.37\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 3.19\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  3.19\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_3 >  -0.72\n",
      "|   |   |   |   |--- feature_15 <= -1.05\n",
      "|   |   |   |   |   |--- feature_8 <= 3.20\n",
      "|   |   |   |   |   |   |--- feature_3 <= 2.07\n",
      "|   |   |   |   |   |   |   |--- feature_3 <= -0.70\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= -0.05\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  -0.05\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_3 >  -0.70\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 <= -1.12\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_5 <= -2.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_14 <= -3.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_14 >  -3.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_5 >  -2.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 >  -1.12\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= -1.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  -1.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_3 >  2.07\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_8 >  3.20\n",
      "|   |   |   |   |   |   |--- feature_2 <= -0.22\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_2 >  -0.22\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_15 >  -1.05\n",
      "|   |   |   |   |   |--- feature_7 <= 0.97\n",
      "|   |   |   |   |   |   |--- feature_9 <= -0.79\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= -0.10\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  -0.10\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_9 >  -0.79\n",
      "|   |   |   |   |   |   |   |--- feature_4 <= -0.72\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= -0.28\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 <= 0.72\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= -1.53\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  -1.53\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 >  0.72\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.91\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.91\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  -0.28\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= 0.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  0.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= -0.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  -0.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_4 >  -0.72\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 <= 0.83\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 <= 2.24\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_11 <= 0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_11 >  0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 >  2.24\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 >  0.83\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  0.97\n",
      "|   |   |   |   |   |   |--- feature_16 <= 0.47\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.62\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 <= 1.05\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= -1.61\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  -1.61\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 <= 0.46\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_16 >  0.46\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 >  1.05\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.09\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.44\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  1.44\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.09\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.62\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 <= 0.16\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.16\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -2.33\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -2.33\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.16\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_15 >  0.16\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 <= 0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.42\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  1.42\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_15 >  0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 <= -0.66\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_6 >  -0.66\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |--- feature_16 >  0.47\n",
      "|   |   |   |   |   |   |   |--- feature_12 <= -2.07\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_12 >  -2.07\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 <= -1.37\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_4 >  -1.37\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 1.18\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 <= 0.40\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_13 >  0.40\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  1.18\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 1.81\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  1.81\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|--- feature_9 >  0.72\n",
      "|   |--- feature_9 <= 1.01\n",
      "|   |   |--- feature_16 <= 0.17\n",
      "|   |   |   |--- feature_3 <= -1.32\n",
      "|   |   |   |   |--- feature_15 <= -2.27\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_15 >  -2.27\n",
      "|   |   |   |   |   |--- feature_0 <= 1.18\n",
      "|   |   |   |   |   |   |--- feature_17 <= -1.91\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_17 >  -1.91\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_0 >  1.18\n",
      "|   |   |   |   |   |   |--- feature_1 <= -0.26\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 5.65\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= -1.99\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_17 <= -1.23\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_17 >  -1.23\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  -1.99\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -1.36\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= -1.93\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  -1.93\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -1.36\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  5.65\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_1 >  -0.26\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= -1.92\n",
      "|   |   |   |   |   |   |   |   |--- feature_3 <= -1.68\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 2.03\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  0.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 >  2.03\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -4.22\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -4.22\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
      "|   |   |   |   |   |   |   |   |--- feature_3 >  -1.68\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  -1.92\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_3 >  -1.32\n",
      "|   |   |   |   |--- feature_5 <= 2.26\n",
      "|   |   |   |   |   |--- feature_9 <= 0.75\n",
      "|   |   |   |   |   |   |--- feature_15 <= -0.69\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_15 >  -0.69\n",
      "|   |   |   |   |   |   |   |--- feature_16 <= -1.32\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_16 >  -1.32\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_9 >  0.75\n",
      "|   |   |   |   |   |   |--- feature_16 <= -0.25\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_16 >  -0.25\n",
      "|   |   |   |   |   |   |   |--- feature_15 <= -1.12\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_15 >  -1.12\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_5 >  2.26\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_16 >  0.17\n",
      "|   |   |   |--- feature_15 <= -2.11\n",
      "|   |   |   |   |--- feature_3 <= -2.03\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_3 >  -2.03\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_15 >  -2.11\n",
      "|   |   |   |   |--- feature_4 <= -0.40\n",
      "|   |   |   |   |   |--- feature_11 <= -3.46\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_11 >  -3.46\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_4 >  -0.40\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_9 >  1.01\n",
      "|   |   |--- feature_15 <= 0.90\n",
      "|   |   |   |--- feature_7 <= -0.27\n",
      "|   |   |   |   |--- feature_9 <= 1.01\n",
      "|   |   |   |   |   |--- feature_2 <= -1.26\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_2 >  -1.26\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_9 >  1.01\n",
      "|   |   |   |   |   |--- feature_15 <= -0.21\n",
      "|   |   |   |   |   |   |--- feature_5 <= 2.61\n",
      "|   |   |   |   |   |   |   |--- feature_14 <= -1.65\n",
      "|   |   |   |   |   |   |   |   |--- feature_14 <= -1.65\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_14 >  -1.65\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_14 >  -1.65\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_5 >  2.61\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 2.66\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  2.66\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_15 >  -0.21\n",
      "|   |   |   |   |   |   |--- feature_16 <= -0.87\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_16 >  -0.87\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_7 >  -0.27\n",
      "|   |   |   |   |--- feature_14 <= -2.56\n",
      "|   |   |   |   |   |--- feature_7 <= -0.26\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_7 >  -0.26\n",
      "|   |   |   |   |   |   |--- feature_15 <= -2.26\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= -0.75\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 <= -0.77\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 <= -0.67\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 3.91\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  3.91\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_13 >  -0.67\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_6 >  -0.77\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  -0.75\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_15 >  -2.26\n",
      "|   |   |   |   |   |   |   |--- feature_17 <= -0.05\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_17 >  -0.05\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 <= 2.19\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= -2.38\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  -2.38\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_5 >  2.19\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 <= 0.70\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_6 >  0.70\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.28\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  1.28\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_14 >  -2.56\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_15 >  0.90\n",
      "|   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "text_representation = tree.export_text(model)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GridSearch for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Set the regularization type (L1, L2, Elastic Net)\n",
    "penalty = 'l1'\n",
    "\n",
    "# Set the regularization strength (C)\n",
    "C = 0.01\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(penalty=penalty, C=C)\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 15], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 15], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10, 15], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear']})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the logistic regression model\n",
    "model = LogisticRegression()\n",
    "#we want to tune the value of C. \n",
    "\n",
    "# Create the hyperparameters to tune\n",
    "hyperparameters = {'C': [0.1, 1, 10, 15], 'penalty': ['l1', 'l2'], 'solver':['liblinear']} #we only used liblinear becayse it's compatible with both l1 and l2\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, hyperparameters, cv=5) #cv Determines the cross-validation splitting strategy.\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters/estimators\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have 40 tries because it's 4 C's, 2 penalties, and 5 splits: 4 x 2 x 5 = 40\n",
    "- GridSearch states that the best hyperparameter setting is `{'C': 10, 'penalty': 'l2'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **While Lasso and Ridge regression are often considered as standalone models, they're more accurately techniques for regularization. Regularization involves adding a penalty term to the loss function of a model to prevent overfitting and improve generalization.**\n",
    "\n",
    "**Here are the key algorithms that commonly employ Lasso and Ridge regularization:**\n",
    "\n",
    "**1. Linear Regression:**\n",
    "\n",
    "- **Original form:** Simplest model for predicting a continuous response variable from one or more predictor variables.\n",
    "- **Overfitting issue:** Can overfit when features are correlated or dataset is noisy.\n",
    "- **Regularization:** Lasso or Ridge penalty can be added to the cost function to shrink coefficients and reduce overfitting.\n",
    "\n",
    "**2. Logistic Regression:**\n",
    "\n",
    "- **Classification model:** Used for predicting a binary outcome.\n",
    "- **Regularization:** Lasso or Ridge penalty can help prevent overfitting and improve generalization.\n",
    "\n",
    "**3. Support Vector Machines (SVMs):**\n",
    "\n",
    "- **Versatile model:** Handle both classification and regression tasks.\n",
    "- **Regularization:** Lasso or Ridge penalty can be incorporated into the SVM optimization problem to improve generalization.\n",
    "\n",
    "**4. Elastic Net:**\n",
    "\n",
    "- **Hybrid approach:** Combines L1 (Lasso) and L2 (Ridge) penalties for a more flexible regularization strategy.\n",
    "- **Benefits:** Offers a balance between feature selection (Lasso) and coefficient shrinkage (Ridge).\n",
    "\n",
    "**5. Other Algorithms:**\n",
    "\n",
    "- **Generalization technique:** Lasso and Ridge regularization can be applied to various other algorithms, including:\n",
    "    - Neural networks\n",
    "    - Decision trees\n",
    "    - Ensemble methods\n",
    "\n",
    "**Image illustrating Lasso and Ridge regression:**\n",
    "\n",
    "[Image of Lasso and Ridge regression regularization paths]\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "- Lasso and Ridge regularization are powerful tools for improving model generalization and preventing overfitting.\n",
    "- They're applicable to a wide range of machine learning algorithms, not just linear regression.\n",
    "- The choice between Lasso and Ridge depends on the specific problem and dataset characteristics.\n",
    "- Elastic Net offers a flexible combination of both approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>68 Studley St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>3/09/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8014</td>\n",
       "      <td>144.9958</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>18/659 Victoria St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VB</td>\n",
       "      <td>Rounds</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8114</td>\n",
       "      <td>145.0116</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb             Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford       68 Studley St      2    h        NaN     SS  Jellis   \n",
       "1  Abbotsford        85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "2  Abbotsford     25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "3  Abbotsford  18/659 Victoria St      3    u        NaN     VB  Rounds   \n",
       "4  Abbotsford        5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "\n",
       "        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  3/09/2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
       "1  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "2  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "3  4/02/2016       2.5    3067.0  ...       2.0  1.0       0.0           NaN   \n",
       "4  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
       "\n",
       "   YearBuilt         CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN  Yarra City Council  -37.8014    144.9958  Northern Metropolitan   \n",
       "1        NaN  Yarra City Council  -37.7996    144.9984  Northern Metropolitan   \n",
       "2     1900.0  Yarra City Council  -37.8079    144.9934  Northern Metropolitan   \n",
       "3        NaN  Yarra City Council  -37.8114    145.0116  Northern Metropolitan   \n",
       "4     1900.0  Yarra City Council  -37.8093    144.9944  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "3        4019.0  \n",
       "4        4019.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Melbourne_housing_FULL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34857, 21)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1480000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1035000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>VB</td>\n",
       "      <td>Rounds</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1465000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb  Rooms Type Method SellerG  Distance  Bedroom2  Bathroom  Car  \\\n",
       "0  Abbotsford      2    h     SS  Jellis       2.5       2.0       1.0  1.0   \n",
       "1  Abbotsford      2    h      S  Biggin       2.5       2.0       1.0  1.0   \n",
       "2  Abbotsford      2    h      S  Biggin       2.5       2.0       1.0  0.0   \n",
       "3  Abbotsford      3    u     VB  Rounds       2.5       3.0       2.0  1.0   \n",
       "4  Abbotsford      3    h     SP  Biggin       2.5       3.0       2.0  0.0   \n",
       "\n",
       "   Landsize  BuildingArea  YearBuilt             Regionname  Propertycount  \\\n",
       "0     126.0           NaN        NaN  Northern Metropolitan         4019.0   \n",
       "1     202.0           NaN        NaN  Northern Metropolitan         4019.0   \n",
       "2     156.0          79.0     1900.0  Northern Metropolitan         4019.0   \n",
       "3       0.0           NaN        NaN  Northern Metropolitan         4019.0   \n",
       "4     134.0         150.0     1900.0  Northern Metropolitan         4019.0   \n",
       "\n",
       "       Price  \n",
       "0        NaN  \n",
       "1  1480000.0  \n",
       "2  1035000.0  \n",
       "3        NaN  \n",
       "4  1465000.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df[['Suburb',  'Rooms', 'Type',  'Method', 'SellerG',\n",
    "        'Distance',  'Bedroom2', 'Bathroom', 'Car',\n",
    "       'Landsize', 'BuildingArea', 'YearBuilt', 'Regionname', 'Propertycount', 'Price']]\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb               0\n",
       "Rooms                0\n",
       "Type                 0\n",
       "Method               0\n",
       "SellerG              0\n",
       "Distance             1\n",
       "Bedroom2          8217\n",
       "Bathroom          8226\n",
       "Car               8728\n",
       "Landsize         11810\n",
       "BuildingArea     21115\n",
       "YearBuilt        19306\n",
       "Regionname           3\n",
       "Propertycount        3\n",
       "Price             7610\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/ds4ljhhn611fn_glg6pp102h0000gq/T/ipykernel_77214/3308839049.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final[imp_col] = df_final[imp_col].fillna(0)\n",
      "/var/folders/3x/ds4ljhhn611fn_glg6pp102h0000gq/T/ipykernel_77214/3308839049.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final.dropna(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Suburb           0\n",
       "Rooms            0\n",
       "Type             0\n",
       "Method           0\n",
       "SellerG          0\n",
       "Distance         0\n",
       "Bedroom2         0\n",
       "Bathroom         0\n",
       "Car              0\n",
       "Landsize         0\n",
       "BuildingArea     0\n",
       "YearBuilt        0\n",
       "Regionname       0\n",
       "Propertycount    0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_col = ['Bedroom2', 'Propertycount', 'Price', 'Bathroom', 'Car'] \n",
    "df_final[imp_col] = df_final[imp_col].fillna(0)\n",
    "\n",
    "df_final.dropna(inplace=True)\n",
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11700, 15)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>Price</th>\n",
       "      <th>...</th>\n",
       "      <th>SellerG_iSell</th>\n",
       "      <th>SellerG_iTRAK</th>\n",
       "      <th>Regionname_Eastern Metropolitan</th>\n",
       "      <th>Regionname_Eastern Victoria</th>\n",
       "      <th>Regionname_Northern Metropolitan</th>\n",
       "      <th>Regionname_Northern Victoria</th>\n",
       "      <th>Regionname_South-Eastern Metropolitan</th>\n",
       "      <th>Regionname_Southern Metropolitan</th>\n",
       "      <th>Regionname_Western Metropolitan</th>\n",
       "      <th>Regionname_Western Victoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>1876000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rooms  Distance  Bedroom2  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "2       2       2.5       2.0       1.0  0.0     156.0          79.0   \n",
       "4       3       2.5       3.0       2.0  0.0     134.0         150.0   \n",
       "6       4       2.5       3.0       1.0  2.0     120.0         142.0   \n",
       "7       4       2.5       3.0       2.0  2.0     400.0         220.0   \n",
       "11      3       2.5       4.0       2.0  0.0     245.0         210.0   \n",
       "\n",
       "    YearBuilt  Propertycount      Price  ...  SellerG_iSell  SellerG_iTRAK  \\\n",
       "2      1900.0         4019.0  1035000.0  ...          False          False   \n",
       "4      1900.0         4019.0  1465000.0  ...          False          False   \n",
       "6      2014.0         4019.0  1600000.0  ...          False          False   \n",
       "7      2006.0         4019.0        0.0  ...          False          False   \n",
       "11     1910.0         4019.0  1876000.0  ...          False          False   \n",
       "\n",
       "    Regionname_Eastern Metropolitan  Regionname_Eastern Victoria  \\\n",
       "2                             False                        False   \n",
       "4                             False                        False   \n",
       "6                             False                        False   \n",
       "7                             False                        False   \n",
       "11                            False                        False   \n",
       "\n",
       "    Regionname_Northern Metropolitan  Regionname_Northern Victoria  \\\n",
       "2                               True                         False   \n",
       "4                               True                         False   \n",
       "6                               True                         False   \n",
       "7                               True                         False   \n",
       "11                              True                         False   \n",
       "\n",
       "    Regionname_South-Eastern Metropolitan  Regionname_Southern Metropolitan  \\\n",
       "2                                   False                             False   \n",
       "4                                   False                             False   \n",
       "6                                   False                             False   \n",
       "7                                   False                             False   \n",
       "11                                  False                             False   \n",
       "\n",
       "    Regionname_Western Metropolitan  Regionname_Western Victoria  \n",
       "2                             False                        False  \n",
       "4                             False                        False  \n",
       "6                             False                        False  \n",
       "7                             False                        False  \n",
       "11                            False                        False  \n",
       "\n",
       "[5 rows x 626 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.get_dummies(df_final) #drop_first=True dummy variable trap\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(columns=['Price'], axis=1)\n",
    "y = df_final['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "reg = LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30376247065671136"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3578246994966935"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+15, tolerance: 4.860e+14\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=50, max_iter=100, tol=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=50, max_iter=100, tol=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=50, max_iter=100, tol=0.1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lasso_reg = linear_model.Lasso(alpha=50, max_iter=100, tol=0.1)\n",
    "lasso_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31284511587890895"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.354052870499735"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
