{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the pre-trained ResNet-50 model as a feature extractor and adds a new classification layer on top of it. The pre-trained layers are frozen, and only the new classification layer is trained.\n",
    "Here's what's happening:\n",
    "- We load the pre-trained ResNet-50 model using models.resnet50(pretrained=True).\n",
    "- We freeze the weights of the pre-trained layers using param.requires_grad = False.\n",
    "- We add a new classification layer on top of the pre-trained model using model.fc = nn.Linear(model.fc.in_features, num_classes).\n",
    "- We move the model to the device (GPU or CPU) using model.to(device).\n",
    "- We define the data transforms and load the dataset (e.g., Flowers dataset).\n",
    "- We create data loaders and define the optimizer and loss function.\n",
    "- We train the model using the pre-trained layers as a feature extractor and the new classification layer as the trainable part.\n",
    "Note that this is just an example code, and you may need to adjust the hyperparameters (e.g., learning rate, batch size, number of epochs) to achieve better results on your specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "# Define the device (GPU or CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add a new classification layer on top of the pre-trained model\n",
    "num_classes = 5  # Replace with the number of classes in your dataset\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define the data transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load the dataset (e.g., Flowers dataset)\n",
    "train_dataset = datasets.ImageFolder('flowers/train', data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder('flowers/val', data_transforms['val'])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item()}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}, Val Loss: {val_loss / len(val_loader)}, Val Acc: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
